{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_words(spellchecker, words, add_to_dict=[]):   \n",
    "    enc = spellchecker.get_dic_encoding()   # get the encoding for later use in decode()\n",
    "\n",
    "    # add custom words to the dictionary\n",
    "    for w in add_to_dict:\n",
    "        spellchecker.add(w)\n",
    "\n",
    "    # auto-correct words\n",
    "    corrected = []\n",
    "    for w in words:\n",
    "        ok = spellchecker.spell(w)   # check spelling\n",
    "        if not ok:\n",
    "            suggestions = spellchecker.suggest(w)\n",
    "            if len(suggestions) > 0:  # there are suggestions\n",
    "                best = suggestions[0].decode(enc)   # best suggestions (decoded to str)\n",
    "                corrected.append(best)\n",
    "            else:\n",
    "                corrected.append(w)  # there's no suggestion for a correct word\n",
    "        else:\n",
    "            corrected.append(w)   # this word is correct\n",
    "\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spellchecker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3692f59de1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspellchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblaxkk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spellchecker' is not defined"
     ]
    }
   ],
   "source": [
    "correct_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.1.0.tar.gz (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.1.0-py3-none-any.whl size=1811976 sha256=061a5f236d8fb7441a40a0d3efa9ced6f7e447a8e41ad73fa1a913360896d52a\n",
      "  Stored in directory: /Users/animeshsrivastava/Library/Caches/pip/wheels/5c/ca/07/626c5585ff2c2c14c5a04e282aaefde7f4b0d6c64ed79ce0eb\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want mens black shoes.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell(\"I watn to buy woemns skrits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want mens black shoes.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell(\"I watn mens blakcc shoess.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoes\n",
      "{'shoes'}\n",
      "black\n",
      "{'blacken', 'blacked', 'blackly', 'blacks', 'blacker', 'blackie', 'black'}\n",
      "want\n",
      "{'wtn', 'wann', 'wath', 'wat', 'watan', 'atn', 'wan', 'want', 'warn', 'watt', 'wain'}\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(['I', 'watn', 'men','blackkk','shoess'])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ekphrasis\n",
      "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.7/site-packages (from ekphrasis) (4.42.1)\n",
      "Requirement already satisfied: colorama in ./opt/anaconda3/lib/python3.7/site-packages (from ekphrasis) (0.4.3)\n",
      "Requirement already satisfied: ujson in ./opt/anaconda3/lib/python3.7/site-packages (from ekphrasis) (1.35)\n",
      "Requirement already satisfied: matplotlib in ./opt/anaconda3/lib/python3.7/site-packages (from ekphrasis) (3.1.3)\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.7/site-packages (from ekphrasis) (3.4.5)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-5.8.tar.gz (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 4.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./opt/anaconda3/lib/python3.7/site-packages (from ekphrasis) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib->ekphrasis) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib->ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib->ekphrasis) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./opt/anaconda3/lib/python3.7/site-packages (from matplotlib->ekphrasis) (2.4.6)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.7/site-packages (from nltk->ekphrasis) (1.14.0)\n",
      "Requirement already satisfied: wcwidth in ./opt/anaconda3/lib/python3.7/site-packages (from ftfy->ekphrasis) (0.1.8)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis) (46.0.0.post20200309)\n",
      "Building wheels for collected packages: ekphrasis, termcolor, ftfy\n",
      "  Building wheel for ekphrasis (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82844 sha256=516c25e8587463ae405a2e81e31ee736e5bada6752f5bbf5137c8a54a94eea7b\n",
      "  Stored in directory: /Users/animeshsrivastava/Library/Caches/pip/wheels/f7/ec/0d/12659e32faf780546945d0120f2c8410eb3efb7426731da88f\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=3b989b169cc98f279d5abb3cf87c5c518dd95f46aade20c80267499c6d0ed9ce\n",
      "  Stored in directory: /Users/animeshsrivastava/Library/Caches/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-5.8-py3-none-any.whl size=45612 sha256=f9b56ddf9bc1e083af406b84fd5e681612cf16a41ebc7cb5e3ea7984a519dc38\n",
      "  Stored in directory: /Users/animeshsrivastava/Library/Caches/pip/wheels/49/1c/fc/8b19700f939810cd8fd9495ae34934b246279791288eda1c31\n",
      "Successfully built ekphrasis termcolor ftfy\n",
      "Installing collected packages: termcolor, ftfy, ekphrasis\n",
      "Successfully installed ekphrasis-0.5.1 ftfy-5.8 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "trousers\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.spellcorrect import SpellCorrector\n",
    "sp = SpellCorrector(corpus=\"english\") \n",
    "print(sp.correct(\"truosers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n",
      "black\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.spellcorrect import SpellCorrector\n",
    "sp = SpellCorrector(corpus=\"english\") \n",
    "print(sp.correct(\"blackk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gingerit\n",
      "  Downloading gingerit-0.8.0-py3-none-any.whl (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.22 in ./opt/anaconda3/lib/python3.7/site-packages (from gingerit) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.22->gingerit) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.22->gingerit) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.22->gingerit) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.22->gingerit) (2019.11.28)\n",
      "Installing collected packages: gingerit\n",
      "Successfully installed gingerit-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gingerit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I watn mens blakcc shoess.',\n",
       " 'result': 'I want men black shoes.',\n",
       " 'corrections': [{'start': 19,\n",
       "   'text': 'shoess',\n",
       "   'correct': 'shoes',\n",
       "   'definition': 'a particular situation'},\n",
       "  {'start': 12,\n",
       "   'text': 'blakcc',\n",
       "   'correct': 'black',\n",
       "   'definition': 'being of the achromatic color of maximum darkness; having little or no hue owing to absorption of almost all incident light'},\n",
       "  {'start': 7,\n",
       "   'text': 'mens',\n",
       "   'correct': 'men',\n",
       "   'definition': 'the force of workers available'},\n",
       "  {'start': 2,\n",
       "   'text': 'watn',\n",
       "   'correct': 'want',\n",
       "   'definition': 'feel or have a desire for; want strongly'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gingerit.gingerit import GingerIt\n",
    "\n",
    "text = 'I watn mens blakcc shoess.'\n",
    "\n",
    "parser = GingerIt()\n",
    "parser.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('blackk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'back',\n",
       " 'backs',\n",
       " 'black',\n",
       " 'blank',\n",
       " 'block',\n",
       " 'blocks',\n",
       " 'lack',\n",
       " 'lacks',\n",
       " 'slack'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known(edits2('blackk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trousers'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates('truosers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
